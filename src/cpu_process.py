#!/usr/bin/env python3
"""
cpu_process.py

ç®€åŒ–çš„èˆªç©ºæ•°æ®å¤„ç†è„šæœ¬ï¼Œæ•´åˆäº†æ•°æ®è¯»å–ã€åæ ‡è½¬æ¢ã€ç‰¹å¾æå–å’Œæ ‡ç­¾åˆå¹¶çš„å…¨æµç¨‹ã€‚
é¿å…ç”Ÿæˆä¸­é—´æ–‡ä»¶ï¼Œæé«˜å¤„ç†æ•ˆç‡ã€‚
"""

import os
import glob
import argparse
import pandas as pd
import numpy as np
from typing import Dict, List, Tuple, Optional, cast
import time
from numpy.typing import ArrayLike

# åœ°çƒå‚æ•° (WGS84)
EARTH_A = 6378137.0
EARTH_E_SQ = 6.69437999014e-3
FT_TO_M = 0.3048
DEFAULT_ALT_FT = 30000.0

class FlightDataProcessor:
    def __init__(self, min_rows: int = 1000, sample_size: int = 100):
        self.min_rows = min_rows
        self.sample_size = sample_size
        self.aircraft_db = None
        
    def load_aircraft_database(self, db_path: str) -> None:
        """åŠ è½½èˆªç©ºå™¨æ•°æ®åº“"""
        if os.path.exists(db_path):
            self.aircraft_db = pd.read_csv(db_path)
            self.aircraft_db['registration'] = (
                self.aircraft_db['registration']
                .astype(str).str.upper().str.strip()
            )
            print(f"âœ… èˆªç©ºå™¨æ•°æ®åº“å·²åŠ è½½: {len(self.aircraft_db)} æ¡è®°å½•")
        else:
            print(f"âš ï¸ èˆªç©ºå™¨æ•°æ®åº“æœªæ‰¾åˆ°: {db_path}")
    
    def geodetic_to_ecef(self, lat: object, lon: object, 
                        alt: object) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
        """å°†åœ°ç†åæ ‡è½¬æ¢ä¸ºECEFåæ ‡"""
        lat_arr = np.asarray(lat, dtype=float)
        lon_arr = np.asarray(lon, dtype=float)
        alt_arr = np.asarray(alt, dtype=float)
        lat_rad = np.radians(lat_arr)
        lon_rad = np.radians(lon_arr)
        N = EARTH_A / np.sqrt(1 - EARTH_E_SQ * np.sin(lat_rad) ** 2)
        
        X = (N + alt_arr) * np.cos(lat_rad) * np.cos(lon_rad)
        Y = (N + alt_arr) * np.cos(lat_rad) * np.sin(lon_rad)
        Z = ((1 - EARTH_E_SQ) * N + alt_arr) * np.sin(lat_rad)
        
        return X, Y, Z
    
    def compute_distance(self, x_list: List[float], y_list: List[float]) -> float:
        """è®¡ç®—è¿ç»­ç‚¹ä¹‹é—´çš„æ¬§å‡ é‡Œå¾—è·ç¦»æ€»å’Œï¼ˆä½¿ç”¨NumPyå®ç°ï¼Œé¿å…SciPyä¾èµ–ï¼‰"""
        if len(x_list) < 2:
            return 0.0
        x = np.asarray(x_list, dtype=float)
        y = np.asarray(y_list, dtype=float)
        dx = np.diff(x)
        dy = np.diff(y)
        return float(np.sum(np.hypot(dx, dy)))
    
    def compute_mean_heading_change(self, heading_series: pd.Series) -> float:
        """è®¡ç®—å¹³å‡èˆªå‘å˜åŒ–ç‡"""
        diffs = heading_series.diff().dropna()
        if diffs.empty:
            return 0.0
        # å¤„ç†è§’åº¦ç¯ç»• [-180, +180]
        wrapped = ((diffs + 180) % 360) - 180
        return np.abs(wrapped).mean()
    
    def preprocess_dataframe(self, df: pd.DataFrame) -> Optional[pd.DataFrame]:
        """é¢„å¤„ç†å•ä¸ªæ•°æ®æ¡†"""
        # æ£€æŸ¥å¿…è¦åˆ—
        if 'ID' not in df.columns or 'Time' not in df.columns:
            return None
            
        # è¿‡æ»¤è¡Œæ•°è¿‡å°‘çš„æ•°æ®
        if len(df) < self.min_rows:
            return None
        
        # æ•°æ®ç±»å‹è½¬æ¢å’Œæ’å€¼
        num_cols = ['Altitude', 'Speed', 'Heading', 'Lat', 'Lon']
        for col in num_cols:
            if col in df.columns:
                df[col] = pd.to_numeric(df[col], errors='coerce')
                df[col] = df[col].interpolate(method='linear', limit_direction='both')
                df[col] = df[col].ffill().bfill()
            else:
                df[col] = np.nan
        
        # å¤„ç†å­—ç¬¦ä¸²åˆ—
        for col in ['Tail', 'Metar']:
            if col in df.columns:
                non_null = df[col].dropna()
                fill_val = non_null.iloc[0] if not non_null.empty else 'UNKNOWN'
                df[col] = df[col].fillna(fill_val)
            else:
                df[col] = 'UNKNOWN'
        
        # æ—¶é—´æˆ³å¤„ç†
        df['timestamp'] = pd.to_datetime(
            df['Date'] + ' ' + df['Time'], errors='coerce'
        )
        df = df.sort_values('timestamp').reset_index(drop=True)
        
        # ECEFåæ ‡è½¬æ¢
        alt_m = np.full(len(df), DEFAULT_ALT_FT * FT_TO_M)
        df['X'], df['Y'], df['Z'] = self.geodetic_to_ecef(
            df['Lat'].to_numpy(dtype=float, copy=False),
            df['Lon'].to_numpy(dtype=float, copy=False),
            alt_m
        )
        
        return df
    
    def extract_features_from_flight(self, df: pd.DataFrame) -> List[Dict]:
        """ä»å•ä¸ªèˆªç­æ•°æ®ä¸­æå–å—ç‰¹å¾"""
        total_rows = len(df)
        blocks = []
        
        for i in range(0, total_rows, self.sample_size):
            end_idx = min(i + self.sample_size, total_rows)
            block = df.iloc[i:end_idx].copy()
            
            if len(block) < 2:
                continue
            
            # æ—¶é—´ç‰¹å¾
            entry_time = block['timestamp'].iloc[0]
            exit_time = block['timestamp'].iloc[-1]
            duration = (exit_time - entry_time).total_seconds()
            
            # è¿åŠ¨ç‰¹å¾
            mean_speed = block['Speed'].mean()
            heading_change = self.compute_mean_heading_change(block['Heading'])
            distance = self.compute_distance(
                block['X'].tolist(), block['Y'].tolist()
            )
            
            # åŸºæœ¬ä¿¡æ¯
            aircraft_id = block['ID'].iloc[0]
            tail = block['Tail'].iloc[0]
            
            blocks.append({
                'ID': aircraft_id,
                'Tail': tail,
                'sample_index': i // self.sample_size,
                'entry_time': entry_time,
                'exit_time': exit_time,
                'duration': duration if not pd.isna(duration) else 0.0,
                'mean_speed': mean_speed if not pd.isna(mean_speed) else 0.0,
                'mean_changeofheading': heading_change,
                'distance': distance
            })
        
        return blocks
    
    def add_aircraft_info(self, df: pd.DataFrame) -> pd.DataFrame:
        """æ·»åŠ èˆªç©ºå™¨ä¿¡æ¯"""
        if self.aircraft_db is None:
            df['icao24'] = 'UNKNOWN'
            df['icaoaircrafttype'] = 'UNKNOWN'
            df['type_code'] = 1
            return df
        
        # æ ‡å‡†åŒ–Tailåˆ—
        df['Tail'] = df['Tail'].astype(str).str.upper().str.strip()
        
        # åˆå¹¶æ•°æ®åº“ä¿¡æ¯
        merged = df.merge(
            self.aircraft_db, 
            left_on='Tail', 
            right_on='registration', 
            how='left'
        )
        
        # å¡«å……ç¼ºå¤±å€¼
        merged['icao24'] = merged['icao24'].fillna('UNKNOWN')
        merged['icaoaircrafttype'] = merged['icaoaircrafttype'].fillna('UNKNOWN')
        merged['type_code'] = pd.factorize(merged['icaoaircrafttype'])[0] + 1
        
        # æ¸…ç†åˆ—
        if 'registration' in merged.columns:
            merged.drop(columns=['registration'], inplace=True)
        
        return merged
    
    def filter_outliers(self, df: pd.DataFrame) -> pd.DataFrame:
        """è¿‡æ»¤åŸºäºæŒç»­æ—¶é—´çš„å¼‚å¸¸å€¼"""
        # è®¡ç®—æ¯ä¸ªIDçš„æŒç»­æ—¶é—´ä¸­ä½æ•°
        duration_median_series = df.groupby('ID')['duration'].median()
        duration_median = duration_median_series.reset_index()
        duration_median.columns = ['ID', 'median_duration']
        df = df.merge(duration_median, on='ID')
        
        # è¿‡æ»¤è¶…è¿‡1.5å€ä¸­ä½æ•°çš„æ•°æ®
        filtered = cast(pd.DataFrame, df[df['duration'] <= 1.5 * df['median_duration']].copy())
        filtered.drop(columns=['median_duration'], inplace=True)
        
        return filtered
    
    def process_files(self, input_path: str, output_file: str, 
                     aircraft_db_path: Optional[str] = None) -> Dict[str, float]:
        """å¤„ç†æ‰€æœ‰æ–‡ä»¶çš„ä¸»å‡½æ•°ï¼Œè¿”å›æ€§èƒ½æŒ‡æ ‡"""
        start_time = time.time()
        
        # åŠ è½½èˆªç©ºå™¨æ•°æ®åº“
        if aircraft_db_path:
            self.load_aircraft_database(aircraft_db_path)
        
        # æŸ¥æ‰¾æ‰€æœ‰CSVæ–‡ä»¶
        pattern = os.path.join(input_path, '**', '*.csv')
        csv_files = glob.glob(pattern, recursive=True)
        
        if not csv_files:
            print(f"âŒ åœ¨ {input_path} ä¸‹æœªæ‰¾åˆ°CSVæ–‡ä»¶")
            return {
                'total_time': 0.0,
                'read_time': 0.0,
                'process_time': 0.0,
                'post_time': 0.0,
                'processed_aircraft': 0,
                'extracted_features': 0,
                'throughput': 0.0,
                'files_processed': 0
            }
        
        print(f"ğŸ“ æ‰¾åˆ° {len(csv_files)} ä¸ªCSVæ–‡ä»¶")
        
        all_features = []
        processed_count = 0
        file_count = 0
        
        # æ•°æ®è¯»å–é˜¶æ®µ
        read_start = time.time()
        data_by_id = {}
        
        for csv_file in csv_files:
            file_count += 1
            try:
                # è®¾ç½® low_memory=False é¿å…æ··åˆç±»å‹è­¦å‘Š
                df = pd.read_csv(csv_file, low_memory=False)
                if 'ID' not in df.columns:
                    continue
                    
                for aircraft_id, group in df.groupby('ID'):
                    if aircraft_id not in data_by_id:
                        data_by_id[aircraft_id] = []
                    data_by_id[aircraft_id].append(group)
                
                # æ˜¾ç¤ºæ–‡ä»¶å¤„ç†è¿›åº¦
                if file_count % 20 == 0:
                    print(f"ğŸ“„ å·²è¯»å– {file_count}/{len(csv_files)} ä¸ªæ–‡ä»¶...")
                    
            except Exception as e:
                print(f"âš ï¸ è·³è¿‡æ–‡ä»¶ {os.path.basename(csv_file)}: {e}")
                continue
        
        read_time = time.time() - read_start
        print(f"âœ… æ–‡ä»¶è¯»å–å®Œæˆï¼Œå…±æ‰¾åˆ° {len(data_by_id)} ä¸ªä¸åŒçš„èˆªç©ºå™¨ID")
        
        # æ•°æ®å¤„ç†é˜¶æ®µ
        process_start = time.time()
        
        for aircraft_id, frames in data_by_id.items():
            try:
                # åˆå¹¶åŒä¸€IDçš„æ‰€æœ‰æ•°æ®
                combined_df = pd.concat(frames, ignore_index=True)
                combined_df = combined_df.drop_duplicates(subset=['Time'])
                
                # é¢„å¤„ç†
                processed_df = self.preprocess_dataframe(combined_df)
                if processed_df is None:
                    continue
                
                # ç‰¹å¾æå–
                features = self.extract_features_from_flight(processed_df)
                all_features.extend(features)
                processed_count += 1
                
                if processed_count % 10 == 0:
                    print(f"âœ… å·²å¤„ç† {processed_count} ä¸ªèˆªç©ºå™¨")
                    
            except Exception as e:
                print(f"âš ï¸ å¤„ç†èˆªç©ºå™¨ {aircraft_id} æ—¶å‡ºé”™: {e}")
                continue
        
        process_time = time.time() - process_start
        
        if not all_features:
            print("âŒ æ²¡æœ‰æå–åˆ°ä»»ä½•ç‰¹å¾")
            return {
                'total_time': time.time() - start_time,
                'read_time': read_time,
                'process_time': process_time,
                'post_time': 0.0,
                'processed_aircraft': processed_count,
                'extracted_features': 0,
                'throughput': 0.0,
                'files_processed': len([f for f in csv_files if os.path.exists(f)])
            }
        
        # åå¤„ç†é˜¶æ®µ
        post_start = time.time()
        
        # è½¬æ¢ä¸ºDataFrame
        features_df = pd.DataFrame(all_features)
        
        # æ·»åŠ èˆªç©ºå™¨ä¿¡æ¯
        features_df = self.add_aircraft_info(features_df)
        
        # è¿‡æ»¤å¼‚å¸¸å€¼
        features_df = self.filter_outliers(features_df)
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        os.makedirs(os.path.dirname(output_file), exist_ok=True)
        
        # ä¿å­˜ç»“æœ
        features_df.to_csv(output_file, index=False)
        
        post_time = time.time() - post_start
        total_time = time.time() - start_time
        
        print(f"ğŸ‰ å¤„ç†å®Œæˆ!")
        print(f"   - å¤„ç†äº† {processed_count} ä¸ªèˆªç©ºå™¨")
        print(f"   - æå–äº† {len(features_df)} ä¸ªç‰¹å¾å—")
        print(f"   - ç»“æœä¿å­˜è‡³: {output_file}")
        
        # è¿”å›æ€§èƒ½æŒ‡æ ‡
        return {
            'total_time': total_time,
            'read_time': read_time,
            'process_time': process_time,
            'post_time': post_time,
            'processed_aircraft': processed_count,
            'extracted_features': len(features_df),
            'throughput': len(features_df) / total_time if total_time > 0 else 0,
            'files_processed': len([f for f in csv_files if os.path.exists(f)])
        }

def main():
    parser = argparse.ArgumentParser(
        description="ç®€åŒ–çš„èˆªç©ºæ•°æ®å¤„ç†è„šæœ¬"
    )
    parser.add_argument(
        "input_path", 
        help="è¾“å…¥æ•°æ®è·¯å¾„ï¼ˆæ”¯æŒé€’å½’æœç´¢CSVæ–‡ä»¶ï¼‰"
    )
    parser.add_argument(
        "output_file", 
        help="è¾“å‡ºç‰¹å¾æ–‡ä»¶è·¯å¾„"
    )
    parser.add_argument(
        "--aircraft-db", 
        help="èˆªç©ºå™¨æ•°æ®åº“CSVæ–‡ä»¶è·¯å¾„", 
        default=None
    )
    parser.add_argument(
        "--min-rows", 
        type=int, 
        default=1000, 
        help="æœ€å°è¡Œæ•°é˜ˆå€¼ (é»˜è®¤: 1000)"
    )
    parser.add_argument(
        "--sample-size", 
        type=int, 
        default=100, 
        help="æ¯ä¸ªç‰¹å¾å—çš„æ ·æœ¬æ•° (é»˜è®¤: 100)"
    )
    
    args = parser.parse_args()
    
    # åˆ›å»ºå¤„ç†å™¨å¹¶è¿è¡Œ
    processor = FlightDataProcessor(
        min_rows=args.min_rows,
        sample_size=args.sample_size
    )
    
    metrics = processor.process_files(
        input_path=args.input_path,
        output_file=args.output_file,
        aircraft_db_path=args.aircraft_db
    )
    
    # è¾“å‡ºæ€§èƒ½æŒ‡æ ‡
    if metrics:
        print("\nğŸ“Š æ€§èƒ½æŒ‡æ ‡:")
        print(f"   æ€»å¤„ç†æ—¶é—´: {metrics['total_time']:.2f} ç§’")
        print(f"   è¯»å–æ—¶é—´: {metrics['read_time']:.2f} ç§’")
        print(f"   å¤„ç†æ—¶é—´: {metrics['process_time']:.2f} ç§’")
        print(f"   åå¤„ç†æ—¶é—´: {metrics['post_time']:.2f} ç§’")
        print(f"   ååé‡: {metrics['throughput']:.2f} ç‰¹å¾/ç§’")

if __name__ == "__main__":
    main()